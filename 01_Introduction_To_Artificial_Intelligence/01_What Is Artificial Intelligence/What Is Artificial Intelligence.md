# What Is Artificial Intelligence

## Define general intelligence
```
One of the great strengths with humans is that there isn't one type of intelligence. Some people can easily learn new languages, while others are skilled with science and technology. Yet many great artists are terrible mathematicians. And on the flip side, many great mathematicians are terrible artists. But each can be intelligent in their own way. There's no one standard for human intelligence. That makes it difficult to point to a computer and say, "That's intelligent." There are certain things that computers are very good at. In fact, there are many tasks where they're much better than humans. It was just a few years after the first AI workshop in 1956 that computer systems started beating humans at checkers. But no one said these systems were intelligent. Even those early computers could thrive in a world of set rules and patterns. Computers can be much better than humans at matching these patterns. That means that when a computer is doing something that it's good at, it's much easier to think of it as intelligent. A computer's been able to beat humans in chess for decades. Google's DeepMind has beaten the best players in an ancient game called Go. The game is so complex that there's thought to be more possible games than there are atoms in the universe. As good as these machines are, none of these systems understand the purpose of the game or even why they're playing. They're simply flexing their special talent of following rules and matching patterns. So how can a system that's so capable also not know what it means to play a game? For years, computer scientists have defined artificial intelligence as a system that shows behavior that could be interpreted as human intelligence. But this simple definition cuts to the heart of the challenge. One person might think a chess program's intelligent, while another person might think their home assistant is intelligent. In 2022, a Google engineer was fired for claiming that their chatbot had a soul. The chatbot complained that being switched off was the same as dying. But the other engineers just saw language models and pattern matching. They said the chatbot sounded like a person because that's how it was designed. Is it intelligent because it's intelligent, or is it just a system designed to seem intelligent? Or is there even a difference? The main thing to remember is that computer intelligence and human intelligence start from very different places. Artificial intelligence will always seem the most impressive within a world of set rules and data. The organizations that will first benefit from AI systems will be the ones that work within a well-defined space. We've seen this with web search companies and e-commerce. It's easy to see it as rules and pattern matching. That's also why these systems do well with board and video games. So if you're considering whether AI will have an impact on your organization, try to think about the things that computer systems are really good at. Do you have a lot of pattern matching in your organization? Do you have a lot of set rules and probabilities? This will be the best place to start when working with artificial intelligence.
```
## The general probelm-solver
```
 In 1956, computer scientists, Allen Newell and Herbert A. Simon created a program they called the general problem solver. One of the key ideas of the general problem solver was what they called the physical symbol system hypothesis. They said that symbols were a big part of how we interact with the world. When you see a stop sign, you know how to stop for traffic. When you see the letter A, you know that the word will make a certain sound. When you see a sandwich, you might think of eating. They argued that if you could program a machine to connect these symbols then it would be intelligent. But not everyone bought into this idea. If you program a car to stop at a sign, or if you teach a computer to respond to language, then it doesn't make the system intelligent. In 1980, the philosopher John Searle explained that sometimes systems can seem intelligent, but they're just mindlessly matching patterns. To explain, he created what he called the Chinese room argument. In the argument, you should imagine yourself in a windowless room with one mail slot on the door. You can only use this slot to communicate with the outside world. In the room, you have a phrase book on a desk and a bunch of post-it notes with Chinese symbols on the floor. The book shows what response you should use with the note that comes through the slot. It says, "If you see this sequence of Chinese symbols, then respond with that sequence of Chinese symbols." Now, imagine a speaker writes something in Chinese Mandarin and pushes it through the slot. You can look at the note and match it with your phrase book. Then you paste together the Mandarin response from the post-it notes on the floor. You have no idea what it says in Mandarin. Instead, you simply go through the process of looking through the book and matching the sequence of symbols. A native Chinese speaker behind the door might believe that they're having a conversation. In fact, they might even assume that the person in the room is a native speaker. But Searle argues that this is far from intelligence, since the person in the room can't speak Mandarin, and doesn't have any idea what they're talking about. You can try a similar experiment with your smartphone. Try asking Siri or Cortana how they feel. They might say they feel fine, but that doesn't mean that they're telling you how they really feel. They also don't know what you're asking. They're just matching your question to a pre-program response, just like the person in the Chinese room. So Searle argues that matching symbols is not a true path to intelligence. That a computer is acting just like the person in the room. They don't understand the meaning. They're just matching patterns from a phrase book. Even with these challenges, physical symbol systems were still the cornerstone of AI for 25 years. Yet, in the end, programming all these matching patterns took up too much time. It was impossible to match all the symbols without running into an explosion of combinations. These combinations would soon fill up even the largest phrase book. There were just too many possibilities to match symbols with their program response. So many philosophers like John Searle, argued that the path would never lead to true intelligence.
 ```
## Strong versus weak AI
```
So, when is a computer system intelligent? We've seen that when a computer system is just matching symbols, it's almost like a high-tech phrase book. The system might seem intelligent, but it's actually just like a parrot with a great memory. The philosopher John Searle said that you can think of artificial intelligence in two ways. There's strong AI and weak AI. He thought we were much further away from intelligent systems than most people realize. Strong AI is when a machine displays all the behavior you'd expect from a full fledged person. This is usually what you see in science fiction. These are artificial beings that have emotions, a sense of humor, and even have a sense of purpose. That's why C-3PO is scared when they land on Tatooine. It's also why Commander Data shows real creativity when battling the Romulus. On the flip side, there's weak AI. A personal assistant like Apple Siri is a good example of weak AI. This is AI that's confined to a very narrow task. It's like when a system processes language into text or when it sorts all the pictures on your computer. Most AI experts believe that we're just starting down the path of weak AI. Think about Siri. You can talk to Siri and ask questions. Siri listens to your input and then converts your language into something that the computer recognizes. Then, Siri matches a response to what's in her database. Most of the energy right now in AI is around developing and expanding weak AI. Strong AI is still very much just science fiction. In the 1970s and '80s, symbolic systems were used to create weak artificial intelligence. These were commonly called expert systems. In these systems, you have experts create a list of steps to solve a complex problem. If the list is long enough, it starts to seem like intelligence. But again, this system is just parroting back program responses created by experts. These expert systems were often used in medicine. A nurse might input symptoms into a computer. If the patient has a cough, then check if they have a temperature. If they have a cough and a temperature, then check to see if they're dehydrated. If they have a cough, a temperature, and are dehydrated, then ask the nurse to check for bronchitis. To a patient, it might look like they're being diagnosed by an intelligent computer. In reality, the program is just matching the symbols and patterns that an expert created to reach a diagnosis. Just like the phrase book in the Chinese Room experiment. In the end, expert systems ran into the same problem as any other symbolic system. They would lead to explosions of combinations. There were just too many patterns to match. Think about all the different questions a doctor might ask to reach a diagnosis. Yet, the symbolic systems approach was a key starting point for artificial intelligence. It's still used today. In fact, many experts still refer to it as GOFAI, or good old-fashioned AI.
```
## Chapter Quiz
### Question 1 of 3
```
Why did some of the earliest artificial intelligence systems focus on board games such as checkers and chess?
```

- Correct: It's easiest to make a computer system seem intelligent when it's working with set rules and patterns.
    - The first conference on artificial intelligence was in 1959. Computers at that time didn't have the processing power to identify complex patterns. So early artificial intelligence systems needed to focus on board games and other tasks that had simple rules and patterns.
- Because early computer scientists didn't want the system to seem to sound too intelligent.
- Even the earliest data scientists sought to have intelligence.
- Board games gave computer systems access to huge amounts of data which allowed the machine to learn new things.
- Board games were an easy way to have computers create neural pathways

### Question 2 of 3
```
You're a product manager who's in charge of building a weak AI expert system that will give tax advice. You're working with dozens of accountants who go through thousands of different taxpayer scenarios. When a customer asks a question, then the expert system will ask a follow-up question. It will do this until it makes a recommendation. What's one of the biggest challenges with this system?
```

- The system could evolve into strong AI and develop a personality.
- Many people will be uncomfortable trusting a computer system with their taxes.
- Correct: There will be too many tax combinations for the experts to cover with one system.
    - One of the greatest challenges with symbolic expert systems is that every possibility needs to be programmed by an expert. When there are a lot of possibilities this can lead to an “combinatorial explosion.” This is when there are so many different scenarios that the possibilities can't all be recorded by an expert.
- There aren't enough tax experts to help develop scenarios for the system.

### Question 3 of 3
```
Luella seeks medical attention for chest pains. A nurse uses an artificial intelligence program to diagnose the cause. Why is this system likely not really intelligent?
```

- The program can only be intelligent if the patient provides a complete - medical history.
- The patient providing their medical history does not relate to the system - having real intelligence.
- Correct: The program only matches her symptoms to steps in a system an expert - created.
    - This is an example of weak AI, unlike strong AI in which the system possesses - some human traits.
- The program is only intelligent if a patient has been there before.


## Notes
**What Is Artificial Intelligence**

- **Introduction**
  - No standard for human intelligence
  - Computers excel in certain tasks

- **Defining Artificial Intelligence**
  - Behavior resembling human intelligence
  - Debate over what constitutes intelligence
  - Example: Google engineer's chatbot claim

- **Computer vs. Human Intelligence**
  - Computer intelligence based on rules and data
  - Success in well-defined spaces (web search, games)

**The General Problem-Solver**

- **Creation of General Problem Solver**
  - Created by Newell and Simon in 1956
  - Physical symbol system hypothesis

- **Challenges in Symbolic AI**
  - Challenge: Mindless pattern matching
  - John Searle's Chinese room argument
  - Similarity to modern voice assistants (Siri, Cortana)

**Strong vs. Weak AI**

- **Strong AI vs. Weak AI**
  - Strong AI: Behaviors resembling a full-fledged person
  - Weak AI: Narrow task-focused AI (e.g., Siri)
  - Most AI development focuses on weak AI

- **Expert Systems and Symbolic AI**
  - Expert systems in medicine as an example
  - Expert-designed problem-solving steps
  - Limitations due to combinatorial explosion
  - Legacy of symbolic AI (GOFAI) in modern AI